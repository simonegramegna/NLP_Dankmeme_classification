{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"2iBziwmskddV","outputId":"e9ea7915-b678-46b6-fb5f-86d31735cfe0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683479652989,"user_tz":-120,"elapsed":75216,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"source":["!pip install -U spaCy\n","!python -m spacy download en_core_web_lg"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: spaCy in /usr/local/lib/python3.10/dist-packages (3.5.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (4.65.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.0.12)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (23.1)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.4.6)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.0.7)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.10.7)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.0.8)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.27.1)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spaCy) (8.1.9)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (0.7.0)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.0.4)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.3.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.0.8)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.0.9)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.1.1)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spaCy) (6.3.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spaCy) (67.7.2)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.22.4)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (0.10.1)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spaCy) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (2022.12.7)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spaCy) (0.0.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spaCy) (0.7.9)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spaCy) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spaCy) (2.1.2)\n","2023-05-07 17:13:07.572515: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting en-core-web-lg==3.5.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl (587.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.5.0) (3.5.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.1.2)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.12)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (6.3.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.22.4)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.9)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.7)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.65.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.10.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.9)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.8)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.4.6)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.10.7)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (23.1)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.1.1)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.27.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.8)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (67.7.2)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.12)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.0.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.9)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.2)\n","Installing collected packages: en-core-web-lg\n","Successfully installed en-core-web-lg-3.5.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_lg')\n","2023-05-07 17:13:40.266120: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting it-core-news-lg==3.5.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_lg-3.5.0/it_core_news_lg-3.5.0-py3-none-any.whl (567.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m567.9/567.9 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from it-core-news-lg==3.5.0) (3.5.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (1.0.9)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (2.0.8)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (2.0.7)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (2.4.6)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (8.1.9)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (3.0.12)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (3.3.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (3.0.8)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (1.0.4)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (0.7.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (1.22.4)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (4.65.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (1.10.7)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (67.7.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (2.27.1)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (6.3.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (0.10.1)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (1.1.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (23.1)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (2.0.12)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (0.0.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (0.7.9)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (2.1.2)\n","Installing collected packages: it-core-news-lg\n","Successfully installed it-core-news-lg-3.5.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('it_core_news_lg')\n"]}]},{"cell_type":"markdown","metadata":{"id":"eboUh4S-lXDL"},"source":["# spaCy tutorial"]},{"cell_type":"markdown","metadata":{"id":"GOOjE-sMlgKR"},"source":["*Notice that the installation doesn’t automatically download the English model. We need to do that ourselves. (python -m spacy download en_core_web_lg)*\n","\n","Hello World in spaCy"]},{"cell_type":"code","metadata":{"id":"v6qfXBODpGvF","outputId":"e4196cef-9f1c-412c-f217-e2b81dc4f9be","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683479660042,"user_tz":-120,"elapsed":3423,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"source":["import spacy\n","nlp = spacy.load('en_core_web_lg')\n","doc = nlp('Hello World!')\n","for token in doc:\n","    print(token.text)"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Hello\n","World\n","!\n"]}]},{"cell_type":"markdown","metadata":{"id":"vtf0Np7Ypntm"},"source":["spaCy preserves this “link” between the word and its place in the raw text. Here’s how to get the exact index of a word:"]},{"cell_type":"code","metadata":{"id":"RfkVc7TKpoeu","outputId":"65cce432-0d99-4f13-95a9-4b80d55008ed","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683479662465,"user_tz":-120,"elapsed":300,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"source":["for token in doc:\n","    print(token.text + ' ', token.idx)"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Hello  0\n","World  6\n","!  11\n"]}]},{"cell_type":"markdown","metadata":{"id":"2Qa9B12LuUnT"},"source":["The **Token** class exposes a lot of word-level attributes. Here are a few examples:"]},{"cell_type":"code","metadata":{"id":"fxK2cH9ruV48","outputId":"b6f0a038-1058-47ca-8efd-62a82d266fbb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683479664470,"user_tz":-120,"elapsed":250,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"source":["doc = nlp(\"Next week I'll be in Rome.\")\n","for token in doc:\n","    print(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\t{6}\\t{7}\".format(\n","        token.text,\n","        token.idx,\n","        token.lemma_,\n","        token.is_punct,\n","        token.is_space,\n","        token.shape_,\n","        token.pos_,\n","        token.tag_\n","    ))"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Next\t0\tnext\tFalse\tFalse\tXxxx\tADJ\tJJ\n","week\t5\tweek\tFalse\tFalse\txxxx\tNOUN\tNN\n","I\t10\tI\tFalse\tFalse\tX\tPRON\tPRP\n","'ll\t11\twill\tFalse\tFalse\t'xx\tAUX\tMD\n","be\t15\tbe\tFalse\tFalse\txx\tAUX\tVB\n","in\t18\tin\tFalse\tFalse\txx\tADP\tIN\n","Rome\t21\tRome\tFalse\tFalse\tXxxx\tPROPN\tNNP\n",".\t25\t.\tTrue\tFalse\t.\tPUNCT\t.\n"]}]},{"cell_type":"markdown","metadata":{"id":"aKw3AR3Iunjb"},"source":["## Sentence detection\n","Here’s how to achieve one of the most common NLP tasks with spaCy:"]},{"cell_type":"code","metadata":{"id":"N7AK_uofuobf","outputId":"34028b6c-3cee-4ae4-fd81-312c3b5c222c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683479667000,"user_tz":-120,"elapsed":367,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"source":["doc = nlp(\"These are apples. These are oranges.\")\n"," \n","for sent in doc.sents:\n","    print(sent)"],"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["These are apples.\n","These are oranges.\n"]}]},{"cell_type":"markdown","metadata":{"id":"hr5GaivKuxEt"},"source":["## Part Of Speech Tagging\n","PoS-tagging of a sentence:"]},{"cell_type":"code","metadata":{"id":"0SPCdMJhuxpI","outputId":"51884ab7-fd1d-4b7d-c86c-797b6087f10a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683479669293,"user_tz":-120,"elapsed":385,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"source":["doc = nlp(\"Next week I'll be in Madrid.\")\n","print([(token.text, token.pos_) for token in doc])"],"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["[('Next', 'ADJ'), ('week', 'NOUN'), ('I', 'PRON'), (\"'ll\", 'AUX'), ('be', 'AUX'), ('in', 'ADP'), ('Madrid', 'PROPN'), ('.', 'PUNCT')]\n"]}]},{"cell_type":"markdown","metadata":{"id":"DIwj7h7gu0gs"},"source":["## Named Entity Recognition\n","Doing NER with spaCy is super easy and the pretrained model performs pretty well:"]},{"cell_type":"code","metadata":{"id":"MkbmiqJLu2i8","outputId":"915318e7-1bed-4a88-e720-9011bc2207fe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683479671056,"user_tz":-120,"elapsed":3,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"source":["doc = nlp(\"Next week I'll be in Madrid.\")\n","for ent in doc.ents:\n","    print(ent.text, ent.label_)"],"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Next week DATE\n","Madrid GPE\n"]}]},{"cell_type":"markdown","metadata":{"id":"Wn5sD_9FvEwo"},"source":["You can also view the IOB style tagging of the sentence like this:"]},{"cell_type":"code","metadata":{"id":"NC4ytRWQvFDH","outputId":"0929fddb-7781-4091-9d09-afc8ba41cbb5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683479672712,"user_tz":-120,"elapsed":9,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"source":["doc = nlp(\"Next week I'll be in Madrid.\")\n","iob_tagged = [\n","    (\n","        token.text, \n","        token.tag_, \n","        \"{0}-{1}\".format(token.ent_iob_, token.ent_type_) if token.ent_iob_ != 'O' else token.ent_iob_\n","    ) for token in doc\n","]\n","print(iob_tagged)"],"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["[('Next', 'JJ', 'B-DATE'), ('week', 'NN', 'I-DATE'), ('I', 'PRP', 'O'), (\"'ll\", 'MD', 'O'), ('be', 'VB', 'O'), ('in', 'IN', 'O'), ('Madrid', 'NNP', 'B-GPE'), ('.', '.', 'O')]\n"]}]},{"cell_type":"markdown","metadata":{"id":"14YgcbyvvYaG"},"source":["The spaCy NER also has a healthy variety of entities. You can view the full list here: https://spacy.io/usage/linguistic-features#entity-types"]},{"cell_type":"code","metadata":{"id":"DZgmrVtAvXde","outputId":"dc6fb684-7f23-4fe5-af80-98764f52baa3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683479675034,"user_tz":-120,"elapsed":299,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"source":["doc = nlp(\"I just bought 2 shares at 9 a.m. because the stock went up 30% in just 2 days according to the WSJ\")\n","for ent in doc.ents:\n","    print(ent.text, ent.label_)"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["2 CARDINAL\n","9 a.m. TIME\n","30% PERCENT\n","just 2 days DATE\n","WSJ ORG\n"]}]},{"cell_type":"markdown","metadata":{"id":"5a1O_1KWvkuN"},"source":["Let’s use displaCy to view a beautiful visualization of the Named Entity annotated sentence:"]},{"cell_type":"code","metadata":{"id":"X2s_Om6fvmmt","outputId":"3dd2f86f-ec82-47db-d54f-145f9cc37884","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1683479677420,"user_tz":-120,"elapsed":466,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"source":["from spacy import displacy\n"," \n","doc = nlp('I just bought 2 shares at 9 a.m. because the stock went up 30% in just 2 days according to the WSJ')\n","displacy.render(doc, style='ent', jupyter=True)"],"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I just bought \n","<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    2\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n","</mark>\n"," shares at \n","<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    9 a.m.\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n","</mark>\n"," because the stock went up \n","<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    30%\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n","</mark>\n"," in \n","<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    just 2 days\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n","</mark>\n"," according to the \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    WSJ\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n","</div></span>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"S4gc6A62vvXJ"},"source":["## Chunking\n","spaCy automatically detects noun-phrases as well:"]},{"cell_type":"code","metadata":{"id":"ZUDhlXVDvz1j","outputId":"db1fe5c5-bbd9-429c-ff03-688087023b4d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683479680076,"user_tz":-120,"elapsed":306,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"source":["doc = nlp(\"Wall Street Journal just published an interesting piece on crypto currencies\")\n","for chunk in doc.noun_chunks:\n","    print(chunk.text, chunk.label_, chunk.root.text)"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Wall Street Journal NP Journal\n","an interesting piece NP piece\n","crypto currencies NP currencies\n"]}]},{"cell_type":"markdown","metadata":{"id":"xvlq8h5WwKH4"},"source":["Notice how the chunker also computes the root of the phrase, the main word of the phrase."]},{"cell_type":"markdown","metadata":{"id":"8O1Uqf3DwBNF"},"source":["## Dependency Parsing\n","\n","Let’s see the dependency parser in action:"]},{"cell_type":"code","metadata":{"id":"h2OZOPInwLWF","outputId":"b169fa3d-ff8b-4505-a05b-c34e8f399831","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683479683044,"user_tz":-120,"elapsed":800,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"source":["doc = nlp('Wall Street Journal just published an interesting piece on crypto currencies')\n"," \n","for token in doc:\n","    print(\"{0}/{1} <--{2}-- {3}/{4}\".format(\n","        token.text, token.tag_, token.dep_, token.head.text, token.head.tag_))"],"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Wall/NNP <--compound-- Street/NNP\n","Street/NNP <--compound-- Journal/NNP\n","Journal/NNP <--nsubj-- published/VBD\n","just/RB <--advmod-- published/VBD\n","published/VBD <--ROOT-- published/VBD\n","an/DT <--det-- piece/NN\n","interesting/JJ <--amod-- piece/NN\n","piece/NN <--dobj-- published/VBD\n","on/IN <--prep-- piece/NN\n","crypto/NNP <--compound-- currencies/NNS\n","currencies/NNS <--pobj-- on/IN\n"]}]},{"cell_type":"markdown","metadata":{"id":"A4-eoMzRwac4"},"source":["If this doesn’t help visualizing the dependency tree, displaCy comes in handy:"]},{"cell_type":"code","metadata":{"id":"uZKy_d_Nwa3P","outputId":"f6aec982-484e-4160-81f1-ebadb48864f8","colab":{"base_uri":"https://localhost:8080/","height":293},"executionInfo":{"status":"ok","timestamp":1683479685609,"user_tz":-120,"elapsed":312,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"source":["doc = nlp('Wall Street Journal just published an interesting piece on crypto currencies')\n","displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})"],"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"619746d3c9814bb6bf26facab07ebc5b-0\" class=\"displacy\" width=\"1040\" height=\"272.0\" direction=\"ltr\" style=\"max-width: none; height: 272.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Wall</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">Street</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">PROPN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">Journal</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">PROPN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">just</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">ADV</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">published</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">VERB</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">an</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">DET</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">interesting</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">ADJ</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">piece</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">NOUN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">on</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">ADP</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">crypto</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">PROPN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">currencies</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NOUN</tspan>\n","</text>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-619746d3c9814bb6bf26facab07ebc5b-0-0\" stroke-width=\"2px\" d=\"M70,137.0 C70,92.0 130.0,92.0 130.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-619746d3c9814bb6bf26facab07ebc5b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M70,139.0 L62,127.0 78,127.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-619746d3c9814bb6bf26facab07ebc5b-0-1\" stroke-width=\"2px\" d=\"M160,137.0 C160,92.0 220.0,92.0 220.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-619746d3c9814bb6bf26facab07ebc5b-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M160,139.0 L152,127.0 168,127.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-619746d3c9814bb6bf26facab07ebc5b-0-2\" stroke-width=\"2px\" d=\"M250,137.0 C250,47.0 405.0,47.0 405.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-619746d3c9814bb6bf26facab07ebc5b-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M250,139.0 L242,127.0 258,127.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-619746d3c9814bb6bf26facab07ebc5b-0-3\" stroke-width=\"2px\" d=\"M340,137.0 C340,92.0 400.0,92.0 400.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-619746d3c9814bb6bf26facab07ebc5b-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M340,139.0 L332,127.0 348,127.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-619746d3c9814bb6bf26facab07ebc5b-0-4\" stroke-width=\"2px\" d=\"M520,137.0 C520,47.0 675.0,47.0 675.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-619746d3c9814bb6bf26facab07ebc5b-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M520,139.0 L512,127.0 528,127.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-619746d3c9814bb6bf26facab07ebc5b-0-5\" stroke-width=\"2px\" d=\"M610,137.0 C610,92.0 670.0,92.0 670.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-619746d3c9814bb6bf26facab07ebc5b-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M610,139.0 L602,127.0 618,127.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-619746d3c9814bb6bf26facab07ebc5b-0-6\" stroke-width=\"2px\" d=\"M430,137.0 C430,2.0 680.0,2.0 680.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-619746d3c9814bb6bf26facab07ebc5b-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M680.0,139.0 L688.0,127.0 672.0,127.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-619746d3c9814bb6bf26facab07ebc5b-0-7\" stroke-width=\"2px\" d=\"M700,137.0 C700,92.0 760.0,92.0 760.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-619746d3c9814bb6bf26facab07ebc5b-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M760.0,139.0 L768.0,127.0 752.0,127.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-619746d3c9814bb6bf26facab07ebc5b-0-8\" stroke-width=\"2px\" d=\"M880,137.0 C880,92.0 940.0,92.0 940.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-619746d3c9814bb6bf26facab07ebc5b-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M880,139.0 L872,127.0 888,127.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-619746d3c9814bb6bf26facab07ebc5b-0-9\" stroke-width=\"2px\" d=\"M790,137.0 C790,47.0 945.0,47.0 945.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-619746d3c9814bb6bf26facab07ebc5b-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M945.0,139.0 L953.0,127.0 937.0,127.0\" fill=\"currentColor\"/>\n","</g>\n","</svg></span>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"46M5S00nwmK9"},"source":["Word Vectors\n","------------------\n","\n","spaCy comes shipped with a Word Vector model as well. We’ll need to download a larger model for that: *(python -m spacy download en_core_web_lg)*\n","\n","The vectors are attached to spaCy objects: Token, Lexeme (a sort of unnatached token, part of the vocabulary), Span and Doc. The multi-token objects average its constituent vectors.\n","\n","Here are a few properties word vectors have:\n","1. If two words are similar, they appear in similar contexts\n","2. Word vectors are computed taking into account the context (surrounding words)\n","3. Given the two previous observations, similar words should have similar word vectors\n","4. Using vectors we can derive relationships (relatedness) between words\n","\n","Let’s see how we can access the embedding of a word in spaCy:"]},{"cell_type":"code","metadata":{"id":"YJDYKB84xV2C","outputId":"391bee34-4ac9-486e-8352-000644f1d81a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683479694724,"user_tz":-120,"elapsed":381,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"source":["print(nlp.vocab['cat'].vector)"],"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["[ 3.7032e+00  4.1982e+00 -5.0002e+00 -1.1322e+01  3.1702e-02 -1.0255e+00\n"," -3.0870e+00 -3.7327e+00  5.3875e-01  3.5679e+00  6.9276e+00  1.5793e+00\n","  5.1188e-01  3.1868e+00  6.1534e+00 -4.8941e+00 -2.9959e-01 -3.6276e+00\n","  2.3825e+00 -1.4402e+00 -4.7577e+00  4.3607e+00 -4.9814e+00 -3.6672e+00\n"," -1.8052e+00 -2.1888e+00 -4.2875e+00  5.5712e+00 -5.2875e+00 -1.8346e+00\n"," -2.2015e+00 -7.7091e-01 -4.8260e+00  1.2464e+00 -1.7945e+00 -8.1280e+00\n","  1.9994e+00  1.1413e+00  3.8032e+00 -2.8783e+00 -4.2136e-01 -4.4177e+00\n","  7.7456e+00  4.9535e+00  1.7402e+00  1.8275e-01  2.4218e+00 -3.1496e+00\n"," -3.8057e-02 -2.9818e+00  8.3396e-01  1.1531e+01  3.5684e+00  2.5970e+00\n"," -2.8438e+00  3.2755e+00  4.5674e+00  3.2219e+00  3.4206e+00  1.1200e-01\n","  1.0303e-01 -5.8396e+00  4.6370e-01  2.7750e+00 -5.3713e+00 -5.0247e+00\n"," -2.0212e+00  5.8772e-01  1.1569e+00  1.3224e+00  4.3994e+00  2.0444e+00\n","  2.1343e+00 -1.9023e+00  2.1469e+00 -2.9085e+00  4.8429e-01 -3.3544e-01\n","  1.4484e+00 -1.5770e+00 -1.1307e+00  2.8320e+00  6.2041e-01  3.7994e+00\n"," -3.1162e-01 -6.9221e+00  7.1342e+00  7.2441e+00 -8.9326e+00 -2.7927e+00\n","  2.6613e-01  6.7547e-01  6.7293e+00 -5.8127e+00  3.1567e+00 -1.0634e+00\n"," -1.5733e+00  1.3534e+00  3.9218e-01 -8.7077e+00  3.4229e-02  3.3251e+00\n","  4.6713e+00  1.1865e-02  9.8345e-01 -5.3206e-02 -9.1613e+00  6.0161e+00\n"," -2.2223e+00  2.5015e+00 -6.0702e-01 -3.6344e-02  7.1884e+00 -1.4431e+00\n","  2.6156e+00 -1.0148e+00  4.1225e+00 -1.8472e+00  4.6292e+00 -2.6506e+00\n"," -1.8937e+00  4.1749e+00 -9.6644e+00 -2.4813e+00 -2.7637e+00 -1.0624e+00\n","  3.5988e+00  4.9833e+00  6.4499e-01  2.5784e-01  9.8727e-01 -4.2485e+00\n","  3.4272e-01 -2.2270e+00 -1.8957e+00  8.0796e-01 -2.0265e+00 -6.1828e+00\n"," -2.2378e+00  2.8216e+00 -2.0050e+00 -3.8924e+00 -2.9364e-01 -1.6128e+00\n"," -6.7874e-01 -1.9855e+00  1.8221e-01  2.1575e+00  4.9825e-01 -1.7326e+00\n","  4.7886e+00  2.9904e+00  8.3447e-01 -4.7417e+00  2.4697e+00  1.3751e+00\n","  4.5358e+00  6.5386e-01  5.5413e+00  2.3963e+00  1.0031e+00 -8.0664e-01\n"," -1.4126e+00  2.8689e+00 -8.7339e+00 -2.7457e+00 -3.1805e-01 -2.4484e-01\n","  3.7117e+00 -1.8636e+00  2.9959e-01  6.5062e-02 -1.5682e+00  1.5876e+00\n","  6.9224e-01 -6.7734e+00  3.1065e+00  2.3973e+00 -3.5138e+00  3.4460e+00\n","  3.4252e+00 -5.1906e+00 -6.9372e-01  1.9435e+00 -1.5669e-01  1.9710e+00\n","  8.7743e-01 -8.3110e+00 -4.0306e-01 -5.0165e+00 -5.6309e-02  4.9249e+00\n"," -7.1053e+00 -5.2338e+00  2.3535e+00 -2.5255e+00 -2.7785e+00  5.0149e+00\n"," -2.8405e+00 -1.8614e+00  2.8818e-03  1.3281e+00  1.0194e+00  3.5155e+00\n","  2.7971e-01  1.3251e+00  1.4386e+00 -6.1719e-01 -2.6864e+00 -3.9613e+00\n","  4.5749e+00 -1.0939e+00  1.3289e+00 -9.5484e-01 -5.4675e+00  2.1607e+00\n","  5.0715e-01  1.4860e-01 -4.8571e+00 -2.2213e+00 -2.3498e-01 -4.2629e+00\n"," -8.7002e-01  3.3796e+00 -4.3989e+00  6.1047e+00  3.7927e+00 -6.0760e+00\n","  3.1840e+00 -8.3104e-01 -5.4015e+00 -6.2916e+00  1.2497e+00  1.8026e+00\n"," -3.4535e+00 -2.1652e-01 -1.4958e+00  5.7946e-01  2.2505e+00  2.0868e+00\n","  3.9621e-01  1.6076e+00  4.0635e+00 -3.4088e+00 -1.0590e+00 -3.6376e+00\n","  2.0501e+00  1.4785e+00 -1.8906e+00 -2.6215e-01 -5.1386e+00  3.7029e+00\n"," -1.8151e+00 -3.2759e+00 -5.1866e+00  2.5485e-01 -4.5696e+00  1.0147e+01\n"," -3.0195e+00 -2.4640e+00  7.5459e-01 -5.6395e+00 -5.4095e+00 -2.4363e+00\n"," -4.3922e-01 -4.0911e+00 -3.5194e+00  1.8031e+00 -1.3644e-01  6.7990e+00\n","  5.8461e+00  5.3452e-01  1.1042e+00  3.5698e+00  4.4668e+00 -2.4537e+00\n"," -2.1832e+00  1.5293e+00 -1.9414e+00 -8.8675e-02 -1.1825e+00 -3.9996e+00\n","  2.8077e+00 -1.8000e+00  4.2545e+00 -1.3813e+00 -2.2921e+00  3.7889e+00\n"," -1.5837e+00 -7.2078e-01  4.7743e+00 -3.0923e+00  8.4709e+00  3.0132e-01\n"," -5.6173e+00 -5.4610e-01 -4.8459e+00  6.0303e+00 -6.9664e+00  3.1445e+00]\n"]}]},{"cell_type":"markdown","metadata":{"id":"0QlrERavxhhJ"},"source":["There’s a really famous example of word embedding math: \"man\" - \"woman\" + \"queen\" = \"king\". It sounds pretty crazy to be true, so let’s test that out:"]},{"cell_type":"code","metadata":{"id":"PfQNit67xiER","outputId":"d4984758-2437-476e-82d1-04e8ad87b054","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683479730764,"user_tz":-120,"elapsed":312,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"source":["from scipy import spatial\n"," \n","cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n"," \n","man = nlp.vocab['man'].vector\n","woman = nlp.vocab['woman'].vector\n","queen = nlp.vocab['queen'].vector\n","king = nlp.vocab['king'].vector\n"," \n","# We now need to find the closest vector in the vocabulary to the result of \"man\" - \"woman\" + \"queen\"\n","maybe_king = man - woman + queen\n","computed_similarities = []\n"," \n","for word in nlp.vocab:\n","    # Ignore words without vectors\n","    if not word.has_vector:\n","        continue\n"," \n","    similarity = cosine_similarity(maybe_king, word.vector)\n","    computed_similarities.append((word, similarity))\n","\n","computed_similarities = sorted(computed_similarities, key=lambda item: -item[1])\n","print([w[0].text for w in computed_similarities[:10]])"],"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["['queen', 'man', 'king', 'woman', 'he', 'nothin’', \"'cause\", \"'Cause\", 'He', 'That']\n"]}]},{"cell_type":"markdown","metadata":{"id":"5XFNQ-FjxuQN"},"source":["Computing Similarity\n","---------------------------\n","\n","Based on the word embeddings, spaCy offers a similarity interface for all of it’s building blocks: Token, Span, Doc and Lexeme. Here’s how to use that similarity interface:"]},{"cell_type":"code","metadata":{"id":"2BYg824RxyBF","outputId":"53799e11-3cfc-4c25-fa81-6fec7e02b944","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683479790500,"user_tz":-120,"elapsed":291,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"source":["apple = nlp.vocab['apple']\n","dog = nlp.vocab['dog']\n","fruit = nlp.vocab['fruit']\n","animal = nlp.vocab['animal']\n"," \n","print(\"sim(dog, animal) =\",dog.similarity(animal))\n","print(\"sim(dog, fruit) =\", dog.similarity(fruit))\n","print(\"sim(apple, fruit) = \", apple.similarity(fruit))\n","print(\"sim(apple, animal) = \", apple.similarity(animal))"],"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["sim(dog, animal) = 0.5192115902900696\n","sim(dog, fruit) = 0.13643456995487213\n","sim(apple, fruit) =  0.6735885739326477\n","sim(apple, animal) =  0.2935677170753479\n"]}]},{"cell_type":"markdown","metadata":{"id":"EUj3bn3nx2Cv"},"source":["Let’s now use this technique on entire texts:"]},{"cell_type":"code","metadata":{"id":"vGHGZ92Ax0X8","outputId":"577c3381-98c7-419d-cb2d-f6e8e88d6f09","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683479803574,"user_tz":-120,"elapsed":308,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"source":["target = nlp(\"Cats are beautiful animals.\")\n"," \n","doc1 = nlp(\"Dogs are awesome.\")\n","doc2 = nlp(\"Some gorgeous creatures are felines.\")\n","doc3 = nlp(\"Dolphins are swimming mammals.\")\n"," \n","print(target.similarity(doc1))\n","print(target.similarity(doc2))\n","print(target.similarity(doc3))"],"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["0.925293344292394\n","0.9067517259890845\n","0.9037427153904276\n"]}]},{"cell_type":"markdown","metadata":{"id":"7stnhdEG1otz"},"source":["Extending spaCy\n","----------------------\n","\n","The entire spaCy architecture is built upon three building blocks: Document (the big encompassing container), Token (most of the time, a word) and Span (set of consecutive Tokens). The extensions you create can add extra functionality to anyone of the these components. There are some examples out there for what you can do. Let’s create an extension ourselves."]},{"cell_type":"markdown","metadata":{"id":"pv0DySlx1y81"},"source":["### Creating Document level Extension"]},{"cell_type":"code","metadata":{"id":"RMQObGdN1uSV","outputId":"469a397e-dc99-4dcb-8bb9-411eb9f77d65","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683479835696,"user_tz":-120,"elapsed":2322,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"source":["import spacy\n","import nltk\n","\n","from spacy.tokens import Doc\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"," \n","nltk.download('vader_lexicon')\n","sentiment_analyzer = SentimentIntensityAnalyzer()\n","def polarity_scores(doc):\n","    return sentiment_analyzer.polarity_scores(doc.text)\n"," \n","Doc.set_extension('polarity_scores', getter=polarity_scores, force=True)\n"," \n","doc = nlp(\"Today, there is the sun and it is a wonderful day!\")\n","print(doc._.polarity_scores)\n"],"execution_count":47,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["{'neg': 0.0, 'neu': 0.693, 'pos': 0.307, 'compound': 0.6114}\n"]}]},{"cell_type":"code","metadata":{"id":"183lR9H945sx","outputId":"43f207ba-04d5-453a-8f8e-646d1b709e9c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683479843609,"user_tz":-120,"elapsed":303,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"source":["doc = nlp(\"Today is a nice day!!!\")\n","print(doc._.polarity_scores)"],"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["{'neg': 0.0, 'neu': 0.449, 'pos': 0.551, 'compound': 0.5684}\n"]}]},{"cell_type":"code","source":["doc = nlp(\"I love my dog, but I hate cats.\")\n","print(doc._.polarity_scores)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x0YIxQZWmuZv","outputId":"7ab1f412-02a4-44ba-c40b-edacf3754367","executionInfo":{"status":"ok","timestamp":1683479849138,"user_tz":-120,"elapsed":515,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["{'neg': 0.433, 'neu': 0.343, 'pos': 0.223, 'compound': -0.5346}\n"]}]},{"cell_type":"markdown","metadata":{"id":"JBidAVbO13iP"},"source":["One can easily create extensions for every component type. Such extensions only have access to the context of that component. What happens if you need the tokenized text along with the Part-Of-Speech tags. Let’s now build a custom pipeline. Pipelines are another important abstraction of spaCy. The nlp object goes through a list of pipelines and runs them on the document. For example the tagger is ran first, then the parser and ner pipelines are applied on the already POS annotated document. Here’s how the nlp default pipeline structure looks like:"]},{"cell_type":"code","metadata":{"id":"taOTb6yq16PB","outputId":"16ea79f3-c86b-4350-a584-baca0e9330e7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683479857434,"user_tz":-120,"elapsed":414,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"source":["print(nlp.pipeline)"],"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x7f99b2cd82e0>), ('tagger', <spacy.pipeline.tagger.Tagger object at 0x7f99b2cd96c0>), ('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x7f99b07428f0>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x7f99b3322300>), ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x7f99b3c4d140>), ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x7f99b0742960>)]\n"]}]},{"cell_type":"markdown","metadata":{"id":"swF1evPI3WQd"},"source":["### Creating a custom pipeline\n","\n","Let’s build a custom pipeline that needs to be applied after the tagger pipeline is ran. We need the POS tags to get the Synset from Wordnet."]},{"cell_type":"code","metadata":{"id":"fP2BLM9O3YlX","outputId":"40ca4e98-1f0b-4287-e1cb-68c30d01896a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683479905359,"user_tz":-120,"elapsed":299,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"source":["from nltk.corpus import wordnet as wn\n","from spacy.tokens import Token\n","from spacy.language import Language \n"," \n","def penn_to_wn(tag):\n","    if tag.startswith('N'):\n","        return 'n'\n"," \n","    if tag.startswith('V'):\n","        return 'v'\n"," \n","    if tag.startswith('J'):\n","        return 'a'\n"," \n","    if tag.startswith('R'):\n","        return 'r'\n"," \n","    return None\n"," \n"," \n","class WordnetPipeline(object):\n","    def __init__(self, nlp):\n","        Token.set_extension('synset', default=None, force=True)\n"," \n","    def __call__(self, doc):\n","        for token in doc:\n","            wn_tag = penn_to_wn(token.tag_)\n","            if wn_tag is None:\n","                continue\n"," \n","            ss = wn.synsets(token.text, wn_tag)[0]\n","            token._.set('synset', ss)\n"," \n","        return doc\n"," \n","nltk.download('wordnet')\n","\n","@Language.factory(\"wordnet_pipe\")\n","def wordnet_pipe(nlp, name):\n","    return WordnetPipeline(nlp)\n"],"execution_count":51,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]}]},{"cell_type":"markdown","source":["Setup the new pipeline."],"metadata":{"id":"uLLELR7eq3oq"}},{"cell_type":"code","source":["nlp.add_pipe(\"wordnet_pipe\")\n","doc = nlp(\"Paris is the awesome capital of France.\")\n"," \n","for token in doc:\n","    print(token.text, token.tag_, token._.synset)\n","\n","# Let’s see how the pipeline structure looks like\n","print(nlp.pipeline)\n","\n","nlp.remove_pipe(\"wordnet_pipe\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0PMTLTuQq5s7","outputId":"a7118dda-42d4-4fbb-eec8-37819d138470","executionInfo":{"status":"ok","timestamp":1683479959118,"user_tz":-120,"elapsed":622,"user":{"displayName":"Pierpaolo Basile","userId":"07888937177955634695"}}},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["Paris NNP Synset('paris.n.01')\n","is VBZ Synset('be.v.01')\n","the DT None\n","awesome JJ Synset('amazing.s.02')\n","capital NN Synset('capital.n.01')\n","of IN None\n","France NNP Synset('france.n.01')\n",". . None\n","[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x7f99b2cd82e0>), ('tagger', <spacy.pipeline.tagger.Tagger object at 0x7f99b2cd96c0>), ('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x7f99b07428f0>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x7f99b3322300>), ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x7f99b3c4d140>), ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x7f99b0742960>), ('wordnet_pipe', <__main__.WordnetPipeline object at 0x7f99b0a85180>)]\n"]},{"output_type":"execute_result","data":{"text/plain":["('wordnet_pipe', <__main__.WordnetPipeline at 0x7f99b0a85180>)"]},"metadata":{},"execution_count":53}]}]}